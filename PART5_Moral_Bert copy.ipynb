{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93cd7ec4",
   "metadata": {
    "id": "93cd7ec4"
   },
   "source": [
    "# Training BERT Classifier for Moralisation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f59648",
   "metadata": {},
   "source": [
    "The steps in this script are identical to PART 4, but it contains the values for epochs set to 5 to show how the model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94c02373",
   "metadata": {
    "id": "94c02373"
   },
   "outputs": [],
   "source": [
    "# import own functions written in moralisation classifier notebook (NB II) saved to .py\n",
    "from finalproject_functions import remove_bad_rows\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import ticker\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "sns.set(style='ticks', font_scale=1.2)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import compute_sample_weight\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e19c9",
   "metadata": {
    "id": "496e19c9"
   },
   "source": [
    "## Read Required Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4aebe3f9",
   "metadata": {
    "id": "4aebe3f9"
   },
   "outputs": [],
   "source": [
    "labelled_posts = pd.read_excel(\"labs_labelled_posts_new.xlsx\")\n",
    "unlabelled_posts = pd.read_csv(\"unlabelled_posts_new.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466bce40",
   "metadata": {
    "id": "466bce40"
   },
   "source": [
    "## Data Preprocessing: Remove Duplicates & NA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4c61074",
   "metadata": {
    "id": "d4c61074"
   },
   "outputs": [],
   "source": [
    "labelled_posts = remove_bad_rows(labelled_posts, \"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1848f1e",
   "metadata": {
    "id": "a1848f1e"
   },
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "377b8dba",
   "metadata": {
    "id": "377b8dba"
   },
   "outputs": [],
   "source": [
    "x_list = labelled_posts[\"title\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c819f5b3",
   "metadata": {
    "id": "c819f5b3"
   },
   "outputs": [],
   "source": [
    "y_list = labelled_posts[\"moral_label\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab5ff0e0",
   "metadata": {
    "id": "ab5ff0e0"
   },
   "outputs": [],
   "source": [
    "# Train Test Split using the preprocessed comments column and the overall morality label. \n",
    "# X_test_f and y_test_f are set aside to test the final model.\n",
    "X_train, X_test_f, y_train, y_test_f = train_test_split(\n",
    "    x_list,\n",
    "    y_list,\n",
    "    test_size=0.2,\n",
    "    random_state=99)\n",
    "\n",
    "# Split the training data again, this time with test size = .25 to achieve a final split of \n",
    "# 60 training data; 20 validation data (this is where baseline is tested on); 20 final testing data (best model testing)\n",
    "X_train_sec, X_val, y_train_sec, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.25,\n",
    "    random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "660f772c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "660f772c",
    "outputId": "4d74eeb3-178f-4692-cfe7-12fcb4b0fab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 588\n",
      "Validation data: 196\n",
      "Test data: 197\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data: {len(X_train_sec)}\")\n",
    "print(f\"Validation data: {len(X_val)}\")\n",
    "print(f\"Test data: {len(X_test_f)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fd131c",
   "metadata": {
    "id": "f0fd131c"
   },
   "source": [
    "## Loading the English-language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "824ccd50",
   "metadata": {
    "id": "824ccd50"
   },
   "outputs": [],
   "source": [
    "bertmodel = 'bert-base-cased'\n",
    "\n",
    "device_name = 'cuda'\n",
    "\n",
    "max_length = 512\n",
    "\n",
    "save_directory = 'moralisation_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e248d3d",
   "metadata": {
    "id": "6e248d3d"
   },
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d932e228",
   "metadata": {
    "id": "d932e228"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(bertmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ce09e1c0",
   "metadata": {
    "id": "ce09e1c0"
   },
   "outputs": [],
   "source": [
    "unique_labels = set(label for label in y_train_sec)\n",
    "label2id = {label: id for id, label in enumerate(unique_labels)}\n",
    "id2label = {id: label for label, id in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "40064fc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40064fc2",
    "outputId": "c67e7559-e187-4ead-96d7-62b49ace4988"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check: \n",
    "label2id.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "86d5d4fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86d5d4fa",
    "outputId": "2a4474a3-04cc-4f6b-bcc2-f60039d5c15f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check: \n",
    "id2label.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "587d9362",
   "metadata": {
    "id": "587d9362"
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(X_train_sec, truncation=True, padding=True, max_length=max_length)\n",
    "val_encodings = tokenizer(X_val, truncation=True, padding=True, max_length=max_length)\n",
    "test_encodings  = tokenizer(X_test_f, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "train_labels_encoded = [label2id[y] for y in y_train_sec]\n",
    "val_labels_encoded = [label2id[y] for y in y_val]\n",
    "test_labels_encoded  = [label2id[y] for y in y_test_f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d03db12",
   "metadata": {
    "id": "0d03db12"
   },
   "source": [
    "## Custom Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01bc131f",
   "metadata": {
    "id": "01bc131f"
   },
   "outputs": [],
   "source": [
    "#Initiate MyDataset Class\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01e457a2",
   "metadata": {
    "id": "01e457a2"
   },
   "outputs": [],
   "source": [
    "#convert the data \n",
    "train_dataset = MyDataset(train_encodings, train_labels_encoded)\n",
    "val_dataset = MyDataset(val_encodings, val_labels_encoded)\n",
    "test_dataset = MyDataset(test_encodings, test_labels_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8886880",
   "metadata": {
    "id": "f8886880"
   },
   "source": [
    "## Pre-Trained Bert Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ee605b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ee605b1",
    "outputId": "29987409-bc5c-4096-9494-6f0123cf088e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_m = AutoModelForSequenceClassification.from_pretrained(bertmodel, num_labels=len(id2label)).to(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebebeff",
   "metadata": {
    "id": "5ebebeff"
   },
   "source": [
    "## Fine-Tuning Bert Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ebcacaa",
   "metadata": {
    "id": "4ebcacaa"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    labels = eval_pred.label_ids\n",
    "    preds = eval_pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average='macro', sample_weight=compute_sample_weight('balanced', labels))\n",
    "    return {'accuracy': acc, 'macro_f1': macro_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c07eefc0",
   "metadata": {
    "id": "c07eefc0"
   },
   "outputs": [],
   "source": [
    "metric_name = 'macro_f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0542f373",
   "metadata": {
    "id": "0542f373"
   },
   "outputs": [],
   "source": [
    "# Instantiate an object of the TrainingArguments class with the following parameters:\n",
    "training_args = TrainingArguments(\n",
    "    \n",
    "    # Number of training epochs\n",
    "    num_train_epochs=5, #setting to 3 epochs, it began to overfit- changed to 2 makes it cut off before overfitting. \n",
    "                        # Ran with 5 to show where it begins overfitting and plot train/validation loss curve.\n",
    "    \n",
    "    # Batch size for training\n",
    "    per_device_train_batch_size=8,\n",
    "    \n",
    "    # Batch size for evaluation\n",
    "    per_device_eval_batch_size=8,\n",
    "    \n",
    "    # Learning rate for optimization\n",
    "    learning_rate=5e-5,\n",
    "    \n",
    "    # Load the best model at the end of training\n",
    "    load_best_model_at_end=True,\n",
    "    \n",
    "    # Metric used for selecting the best model\n",
    "    metric_for_best_model=metric_name,\n",
    "    \n",
    "    # Number of warmup steps for the optimizer\n",
    "    warmup_steps=0,\n",
    "    \n",
    "    # L2 regularization weight decay\n",
    "    weight_decay=0.01, #increased to avoid overfitting \n",
    "    \n",
    "    # Directory to save the fine-tuned model and configuration files\n",
    "    output_dir='./results',\n",
    "    \n",
    "    # Directory to store logs\n",
    "    logging_dir='./logs',\n",
    "    \n",
    "    # Log results every n steps\n",
    "    logging_steps=20,\n",
    "    \n",
    "    # Strategy for evaluating the model during training\n",
    "    evaluation_strategy='steps'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "16921d32",
   "metadata": {
    "id": "16921d32"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_m,                         # the instantiated Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,           # evaluation dataset (usually a validation set; here we just send our test set)\n",
    "    compute_metrics=compute_metrics)      # our custom evaluation function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a29f9c68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 749
    },
    "id": "a29f9c68",
    "outputId": "8af20fcb-40db-4bfc-cddf-eeb31f26f87c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='370' max='370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [370/370 01:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.610400</td>\n",
       "      <td>0.579096</td>\n",
       "      <td>0.729592</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.513500</td>\n",
       "      <td>0.548197</td>\n",
       "      <td>0.760204</td>\n",
       "      <td>0.463043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.547700</td>\n",
       "      <td>0.507165</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.430363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.477800</td>\n",
       "      <td>0.465717</td>\n",
       "      <td>0.790816</td>\n",
       "      <td>0.766985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>0.460456</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.715680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.359700</td>\n",
       "      <td>0.509234</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.696950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.338300</td>\n",
       "      <td>0.681263</td>\n",
       "      <td>0.801020</td>\n",
       "      <td>0.664268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.238100</td>\n",
       "      <td>0.772730</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.708116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.843409</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.777667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.838558</td>\n",
       "      <td>0.831633</td>\n",
       "      <td>0.760963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.713522</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.743461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.144600</td>\n",
       "      <td>0.727510</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.744007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>1.055032</td>\n",
       "      <td>0.801020</td>\n",
       "      <td>0.627503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.223600</td>\n",
       "      <td>0.855415</td>\n",
       "      <td>0.790816</td>\n",
       "      <td>0.727479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.852997</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.717798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.908388</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.721029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.925053</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.721029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.930002</td>\n",
       "      <td>0.826531</td>\n",
       "      <td>0.721029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=370, training_loss=0.26064979233653157, metrics={'train_runtime': 78.1973, 'train_samples_per_second': 37.597, 'train_steps_per_second': 4.732, 'total_flos': 87628314765600.0, 'train_loss': 0.26064979233653157, 'epoch': 5.0})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49a9f6",
   "metadata": {
    "id": "2b49a9f6"
   },
   "source": [
    "## Save fine tuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f53d3331",
   "metadata": {
    "id": "f53d3331"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf539b5",
   "metadata": {
    "id": "5bf539b5"
   },
   "source": [
    "## Testing on Validation Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6e5e044e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "6e5e044e",
    "outputId": "4ab3f2af-e9ee-4f54-c514-9985f8521939"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9317600727081299,\n",
       " 'eval_accuracy': 0.826530612244898,\n",
       " 'eval_macro_f1': 0.7210294205280927,\n",
       " 'eval_runtime': 1.5191,\n",
       " 'eval_samples_per_second': 129.022,\n",
       " 'eval_steps_per_second': 16.457,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0901e3c9",
   "metadata": {
    "id": "0901e3c9"
   },
   "source": [
    "## Evaluate on Test Set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb03f9b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "eb03f9b3",
    "outputId": "b940ef09-84e4-44e6-ca13-b48fbaacc939"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_results = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e39d29c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e39d29c2",
    "outputId": "412ea94c-1448-422b-bc3d-f75286aa45a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 2)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_results.predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3bd849ae",
   "metadata": {
    "id": "3bd849ae"
   },
   "outputs": [],
   "source": [
    "predicted_labels = predicted_results.predictions.argmax(-1) \n",
    "predicted_labels = predicted_labels.flatten().tolist()      \n",
    "predicted_labels = [id2label[l] for l in predicted_labels]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "225caa4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "225caa4d",
    "outputId": "3a6ceb4b-8513-45cd-cb03-2ac1ef51e169"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f5efa709",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5efa709",
    "outputId": "4294754b-89f4-4b3f-c7ec-07ff0ac4b05b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83       128\n",
      "           1       0.75      0.48      0.58        69\n",
      "\n",
      "    accuracy                           0.76       197\n",
      "   macro avg       0.76      0.70      0.71       197\n",
      "weighted avg       0.76      0.76      0.75       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_f, \n",
    "                           predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63d7de",
   "metadata": {
    "id": "5f63d7de"
   },
   "source": [
    "## Evaluation of Final Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "abe35714",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abe35714",
    "outputId": "88968f77-c06c-4f27-c240-a8c497ca4c6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 0\n",
      "REVIEW TEXT: Canada's immigration website just crashed ...\n",
      "\n",
      "LABEL: 1\n",
      "REVIEW TEXT: Media outlets take Trump out of context to suggest he called undocumented immigrants 'animals' ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Immigration as Economic Warfare ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Fontana man sent to prison for posing as an immigration officer ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Trump announces tariffs on Mexico until 'immigration remedied' ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Trump immigration figure changes famous immigrant quote ...\n",
      "\n",
      "LABEL: 1\n",
      "REVIEW TEXT: South Jersey Restaurant Owner Outraged After ‘Don’t Tip Immigrants’ Found Written On Check ...\n",
      "\n",
      "LABEL: 1\n",
      "REVIEW TEXT: Police provide an update on the illegal immigrant fugitive wanted in the murder of a California poli ...\n",
      "\n",
      "LABEL: 1\n",
      "REVIEW TEXT: NEW JERSEY MUSLIM immigrant charged with scouting locations in major U.S. cities for multiple terror ...\n",
      "\n",
      "LABEL: 1\n",
      "REVIEW TEXT: Lawyer: Mollie Tibbetts murder suspect is not an illegal immigrant ...\n",
      "\n",
      "LABEL: 1\n",
      "REVIEW TEXT: ICE Kept 92 Immigrants Shackled On A Plane For Two Days In 'Slave Ship' Conditions, Advocates Say ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: San Francisco hopes to hire lawyers for illegal immigrants ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Mexican ‘DREAMer’ nabbed in immigrant crackdown ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Michigan receiving detained immigrant children as young as 3 months old ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Trump Administration Will Seek To Limit Green Cards For Immigrants Needing Public Aid ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print examples of correct predictions\n",
    "for _true_label, _predicted_label, _text in random.sample(list(zip(y_test_f, predicted_labels, X_test_f)), 20):\n",
    "  if _true_label == _predicted_label:\n",
    "    print('LABEL:', _true_label)\n",
    "    print('REVIEW TEXT:', _text[:100], '...')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8bc82ab5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bc82ab5",
    "outputId": "b06c342e-495a-4508-ca4e-eaaed4324112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE LABEL: 0\n",
      "PREDICTED LABEL: 1\n",
      "REVIEW TEXT: Immigrant Detained After Press Conference ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: A computer engineer who worked under contract for the U.S. Department of Immigration and Customs Enf ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Veterans Day disgrace: Stop deporting immigrants who served ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: H.R.1044/S386 - Fairness for High-Skilled Immigrants Act of 2019: Altruistic Fair Amendment or Giant ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Best News: Immigrants Broke in to Moving Car Transporter ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Trump vows mass immigration arrests, removals of ‘millions of illegal aliens’ starting next week ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: DOCTORS CAUGHT FAKING MEDICAL RECORDS TO HELP IMMIGRANTS GET CITIZENSHIP! ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: US immigration ban: Thousands gather outside airports as anti-Trump protests hit the country ...\n",
      "\n",
      "TRUE LABEL: 0\n",
      "PREDICTED LABEL: 1\n",
      "REVIEW TEXT: San Bernardino massacre yields second immigration fraud conviction - Yahoo News ...\n",
      "\n",
      "TRUE LABEL: 0\n",
      "PREDICTED LABEL: 1\n",
      "REVIEW TEXT: Judge Rules Feds Can’t Block Immigrant Teens From Abortion ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Undocumented immigrant shot, killed by border patrol officer in Texas ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Boston-area judge charged with helping undocumented immigrant escape courthouse to elude ICE ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Police: Undocumented immigrant with extensive criminal history burglarized, squatted in 2 Md. homes ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Recruiter for ICE’s fake university sentenced to 6 months in jail. ICE created the Farmington Univer ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Unholy Escort humanizes immigration debate with Virgin Mary in handcuffs ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Bolsonaro Fraudulently Circumvented Trump’s COVID-19 Immigration Ban to Smuggle His Scandal-Plagued  ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print missclassifications: \n",
    "for _true_label, _predicted_label, _text in random.sample(list(zip(y_test_f, predicted_labels, X_test_f)), 80):\n",
    "  if _true_label != _predicted_label:\n",
    "    print('TRUE LABEL:', _true_label)\n",
    "    print('PREDICTED LABEL:', _predicted_label)\n",
    "    print('REVIEW TEXT:', _text[:100], '...')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
