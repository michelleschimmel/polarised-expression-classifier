{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93cd7ec4",
   "metadata": {
    "id": "93cd7ec4"
   },
   "source": [
    "# Training BERT Classifier for Polarisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ed501",
   "metadata": {},
   "source": [
    "This script contains the training and testing of a BERT model to classify affective polarisation in Reddit comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "94c02373",
   "metadata": {
    "id": "94c02373"
   },
   "outputs": [],
   "source": [
    "# import own functions written in moralisation classifier notebook (NB II) saved to .py\n",
    "from finalproject_functions import remove_bad_rows\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import ticker\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "sns.set(style='ticks', font_scale=1.2)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import compute_sample_weight\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e19c9",
   "metadata": {
    "id": "496e19c9"
   },
   "source": [
    "## Read Required Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "4aebe3f9",
   "metadata": {
    "id": "4aebe3f9"
   },
   "outputs": [],
   "source": [
    "labelled_comments = pd.read_excel(\"labs_labelled_comments.xlsx\")\n",
    "unlabelled_comments = pd.read_csv(\"unlabelled_comments.csv\", delimiter = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466bce40",
   "metadata": {
    "id": "466bce40"
   },
   "source": [
    "## Data Preprocessing: Remove Duplicates & NA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "d4c61074",
   "metadata": {
    "id": "d4c61074"
   },
   "outputs": [],
   "source": [
    "labelled_comments = remove_bad_rows(labelled_comments, \"comment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1848f1e",
   "metadata": {
    "id": "a1848f1e"
   },
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "377b8dba",
   "metadata": {
    "id": "377b8dba"
   },
   "outputs": [],
   "source": [
    "x_list = labelled_comments[\"comment\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "c819f5b3",
   "metadata": {
    "id": "c819f5b3"
   },
   "outputs": [],
   "source": [
    "y_list = labelled_comments[\"AP_label\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "ab5ff0e0",
   "metadata": {
    "id": "ab5ff0e0"
   },
   "outputs": [],
   "source": [
    "# Train Test Split using the preprocessed comments column and the overall morality label. \n",
    "# X_test_f and y_test_f are set aside to test the final model.\n",
    "X_train, X_test_f, y_train, y_test_f = train_test_split(\n",
    "    x_list,\n",
    "    y_list,\n",
    "    test_size=0.2,\n",
    "    random_state=99)\n",
    "\n",
    "# Split the training data again, this time with test size = .25 to achieve a final split of \n",
    "# 60 training data; 20 validation data (this is where baseline is tested on); 20 final testing data (best model testing)\n",
    "X_train_sec, X_val, y_train_sec, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.25,\n",
    "    random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "660f772c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "660f772c",
    "outputId": "1af85271-2356-41b5-9ec7-6f8e32f4c62b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 597\n",
      "Validation data: 200\n",
      "Test data: 200\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data: {len(X_train_sec)}\")\n",
    "print(f\"Validation data: {len(X_val)}\")\n",
    "print(f\"Test data: {len(X_test_f)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fd131c",
   "metadata": {
    "id": "f0fd131c"
   },
   "source": [
    "## Loading the English-language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "824ccd50",
   "metadata": {
    "id": "824ccd50"
   },
   "outputs": [],
   "source": [
    "bertmodel = 'bert-base-cased'\n",
    "\n",
    "device_name = 'cuda'\n",
    "\n",
    "max_length = 512\n",
    "\n",
    "save_directory = 'polarisation_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e248d3d",
   "metadata": {
    "id": "6e248d3d"
   },
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "d932e228",
   "metadata": {
    "id": "d932e228"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(bertmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "ce09e1c0",
   "metadata": {
    "id": "ce09e1c0"
   },
   "outputs": [],
   "source": [
    "#MINE:\n",
    "unique_labels = set(label for label in y_train_sec)\n",
    "label2id = {label: id for id, label in enumerate(unique_labels)}\n",
    "id2label = {id: label for label, id in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "40064fc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40064fc2",
    "outputId": "1b4fb5ea-73f2-45f9-80c1-38b1ba8ae850"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check: \n",
    "label2id.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "86d5d4fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86d5d4fa",
    "outputId": "8b24f7ae-6d9b-4f14-9863-728f4cea6463"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check: \n",
    "id2label.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "587d9362",
   "metadata": {
    "id": "587d9362"
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(X_train_sec, truncation=True, padding=True, max_length=max_length)\n",
    "val_encodings = tokenizer(X_val, truncation=True, padding=True, max_length=max_length)\n",
    "test_encodings  = tokenizer(X_test_f, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "train_labels_encoded = [label2id[y] for y in y_train_sec]\n",
    "val_labels_encoded = [label2id[y] for y in y_val]\n",
    "test_labels_encoded  = [label2id[y] for y in y_test_f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d03db12",
   "metadata": {
    "id": "0d03db12"
   },
   "source": [
    "## Custom Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "01bc131f",
   "metadata": {
    "id": "01bc131f"
   },
   "outputs": [],
   "source": [
    "#Initiate MyDataset Class\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "01e457a2",
   "metadata": {
    "id": "01e457a2"
   },
   "outputs": [],
   "source": [
    "#convert the data \n",
    "train_dataset = MyDataset(train_encodings, train_labels_encoded) #put this into funct.\n",
    "val_dataset = MyDataset(val_encodings, val_labels_encoded) #put this into funct.\n",
    "test_dataset = MyDataset(test_encodings, test_labels_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8886880",
   "metadata": {
    "id": "f8886880"
   },
   "source": [
    "## Pre-Trained Bert Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "9ee605b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ee605b1",
    "outputId": "47f3ee7e-566b-46d9-d3cb-05a7c05c1a57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_a = AutoModelForSequenceClassification.from_pretrained(bertmodel, num_labels=len(id2label)).to(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebebeff",
   "metadata": {
    "id": "5ebebeff"
   },
   "source": [
    "## Fine-Tuning Bert Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "4ebcacaa",
   "metadata": {
    "id": "4ebcacaa"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    labels = eval_pred.label_ids\n",
    "    preds = eval_pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average='macro', sample_weight=compute_sample_weight('balanced', labels))\n",
    "    return {'accuracy': acc, 'macro_f1': macro_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "c07eefc0",
   "metadata": {
    "id": "c07eefc0"
   },
   "outputs": [],
   "source": [
    "metric_name = 'macro_f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "_hSw9SbL5fmt",
   "metadata": {
    "id": "_hSw9SbL5fmt"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"test\", evaluation_strategy=\"steps\", eval_steps=500, disable_tqdm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "0542f373",
   "metadata": {
    "id": "0542f373"
   },
   "outputs": [],
   "source": [
    "# Instantiate an object of the TrainingArguments class with the following parameters:\n",
    "training_args = TrainingArguments(\n",
    "    \n",
    "    # Number of training epochs\n",
    "    num_train_epochs=5, #with higher epochs, the model begins to overfit -- already between epoch 1 and 2 it starts overfitting\n",
    "    \n",
    "    # Batch size for training\n",
    "    per_device_train_batch_size=8,\n",
    "    \n",
    "    # Batch size for evaluation\n",
    "    per_device_eval_batch_size=8,\n",
    "    \n",
    "    # Learning rate for optimization\n",
    "    learning_rate=5e-5, \n",
    "    \n",
    "    # Load the best model at the end of training\n",
    "    load_best_model_at_end=True,\n",
    "    \n",
    "    # Metric used for selecting the best model\n",
    "    metric_for_best_model=metric_name,\n",
    "    \n",
    "    # Number of warmup steps for the optimizer\n",
    "    warmup_steps=0,\n",
    "    \n",
    "    # L2 regularization weight decay\n",
    "    weight_decay=0.1, #regularization weight was increased to minimise overfitting, however, this did not work\n",
    "    \n",
    "    # Directory to save the fine-tuned model and configuration files\n",
    "    output_dir='./results',\n",
    "    \n",
    "    # Directory to store logs\n",
    "    logging_dir='./logs',\n",
    "    \n",
    "    # Log results every n steps\n",
    "    logging_steps=20,\n",
    "    \n",
    "    # Strategy for evaluating the model during training\n",
    "    evaluation_strategy='steps',\n",
    ")\n",
    "\n",
    "#https://towardsdatascience.com/handling-overfitting-in-deep-learning-models-c760ee047c6e\n",
    "#https://towardsdatascience.com/handling-overfitting-in-deep-learning-models-c760ee047c6e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "16921d32",
   "metadata": {
    "id": "16921d32"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_a,                         # the instantiated Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,           # evaluation dataset (usually a validation set; here we just send our test set)\n",
    "    compute_metrics=compute_metrics)      # our custom evaluation function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "a29f9c68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 749
    },
    "id": "a29f9c68",
    "outputId": "04bbd148-5607-4977-ba95-02e7fb8e5457"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 01:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.493800</td>\n",
       "      <td>0.579262</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.576800</td>\n",
       "      <td>0.552687</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.504300</td>\n",
       "      <td>0.568991</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.528500</td>\n",
       "      <td>0.612369</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.434100</td>\n",
       "      <td>0.455225</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.399249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.403500</td>\n",
       "      <td>0.739063</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.352866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.388500</td>\n",
       "      <td>0.663712</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.705496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.274100</td>\n",
       "      <td>0.751172</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.555989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>1.077220</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.499197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.421400</td>\n",
       "      <td>0.910365</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.437614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>0.814422</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.589221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>1.059403</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.470959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>1.078319</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.573696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>1.213862</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.484280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>1.175430</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.543139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.276599</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.515964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>1.255320</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.543139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.237287</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.555989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=0.25877766268452007, metrics={'train_runtime': 98.8746, 'train_samples_per_second': 30.19, 'train_steps_per_second': 3.793, 'total_flos': 785386500249600.0, 'train_loss': 0.25877766268452007, 'epoch': 5.0})"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49a9f6",
   "metadata": {
    "id": "2b49a9f6"
   },
   "source": [
    "## Save fine tuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "f53d3331",
   "metadata": {
    "id": "f53d3331"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf539b5",
   "metadata": {
    "id": "5bf539b5"
   },
   "source": [
    "## Testing on Validation Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "6e5e044e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "6e5e044e",
    "outputId": "5c1930b9-9980-4348-fc61-1385dc06233f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2461990118026733,\n",
       " 'eval_accuracy': 0.78,\n",
       " 'eval_macro_f1': 0.5559887664605376,\n",
       " 'eval_runtime': 1.2721,\n",
       " 'eval_samples_per_second': 157.22,\n",
       " 'eval_steps_per_second': 19.653,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0901e3c9",
   "metadata": {
    "id": "0901e3c9"
   },
   "source": [
    "## Evaluate on Test Set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "eb03f9b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "eb03f9b3",
    "outputId": "f4d8a639-b068-4fe9-d33e-406ca200153f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_results = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e39d29c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e39d29c2",
    "outputId": "31f348d0-847a-4786-bf5a-2ce2b4ecb98f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_results.predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "3bd849ae",
   "metadata": {
    "id": "3bd849ae"
   },
   "outputs": [],
   "source": [
    "predicted_labels = predicted_results.predictions.argmax(-1) \n",
    "predicted_labels = predicted_labels.flatten().tolist()      \n",
    "predicted_labels = [id2label[l] for l in predicted_labels]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "225caa4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "225caa4d",
    "outputId": "3e0a0af5-fe8a-4262-f9ad-ba483780e291"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "f5efa709",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5efa709",
    "outputId": "dbe158d7-d96d-4154-a8d5-113d83a44451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88       164\n",
      "           1       0.44      0.31      0.36        36\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.65      0.61      0.62       200\n",
      "weighted avg       0.78      0.81      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_f, \n",
    "                           predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63d7de",
   "metadata": {
    "id": "5f63d7de"
   },
   "source": [
    "## Evaluation of Final Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "abe35714",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abe35714",
    "outputId": "8436fdb1-58f4-46f4-dcd0-9fb9322a34c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 1\n",
      "REVIEW TEXT: The immigration status of the perpetrators is really the most important part of this story. Thanks f ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Detain the immigrants, now you got slaves . Sell their work and charge the government for keeping th ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Sometimes standing up for yourself has a price.   Sometimes it's a price you can't pay. ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: I can understand the great polarization between the two parties in America. I cannot, however, under ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: This happens when people are arrested. Why the surprise here? ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Advertisers are cowards with skin thinner than tissue paper. News at eleven.\n",
      "\n",
      "I thought we already l ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: It's comforting seeing social progress being reversed... Not like banning the confederate flag. That ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: ..but not Will Smith's Bel Air ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: 'Papers, please. No papers? Off to the camps with you!' ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Mar-a-lago wondering where half their staff went ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: lesson learned here...we can't trust cops. ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: That is what usually happens when you don't show up to work when you're expected to be there, regard ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: I really wish we would freeze immigration for the right reasons, not because cigna demands more cust ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Why?\n",
      "\n",
      "There won't be Mexicans there. They don't give a shit about Cinco de Mayo. It's an American ex ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print examples of correct predictions\n",
    "for _true_label, _predicted_label, _text in random.sample(list(zip(y_test_f, predicted_labels, X_test_f)), 20):\n",
    "  if _true_label == _predicted_label:\n",
    "    print('LABEL:', _true_label)\n",
    "    print('REVIEW TEXT:', _text[:100], '...')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "8bc82ab5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bc82ab5",
    "outputId": "be9020e5-af5b-4d39-d96a-e68eb029a5c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: lol...a whole 450.  Wow.  That'll show those damn dirty liberal cities what's up.  \n",
      "\n",
      "How many of the ...\n",
      "\n",
      "TRUE LABEL: 0\n",
      "PREDICTED LABEL: 1\n",
      "REVIEW TEXT: What's the obsession with illegal immigrants on the DNC side? Don't they understand they are losing  ...\n",
      "\n",
      "TRUE LABEL: 0\n",
      "PREDICTED LABEL: 1\n",
      "REVIEW TEXT: Racists who say they have a black friend be like ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Sounds like something people of /r/conservative would do. ...\n",
      "\n",
      "TRUE LABEL: 0\n",
      "PREDICTED LABEL: 1\n",
      "REVIEW TEXT: 8 yo Mickey Hicks.  \n",
      "6 yo Alyssa Thomas.  \n",
      "Unnamed 2 yo.  \n",
      "9 yo James Robinson \n",
      "  \n",
      "These kids are on ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: The explanation is that they need cars to get from place to place, but why the fuck are we allowing  ...\n",
      "\n",
      "TRUE LABEL: 0\n",
      "PREDICTED LABEL: 1\n",
      "REVIEW TEXT: I wonder if we had mfa would that qualify. Either way shame on us the richest country. I guess we’re ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: The comments on here are just another example of why Trump won.\n",
      "\n",
      "Every country on this planet gets t ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Strip their tax exempt status and these fine Christians will personally drive her to the border and  ...\n",
      "\n",
      "TRUE LABEL: 0\n",
      "PREDICTED LABEL: 1\n",
      "REVIEW TEXT: He is a criminal for being here illegally, those who will break the law of our country to come to it ...\n",
      "\n",
      "TRUE LABEL: 0\n",
      "PREDICTED LABEL: 1\n",
      "REVIEW TEXT: Convicted for criminal fraud AND here illegally.  Yes open your doors, what's the worst that can hap ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Maybe the boss agreed with them, but when people dont show and don't call it really leaves him in th ...\n",
      "\n",
      "TRUE LABEL: 0\n",
      "PREDICTED LABEL: 1\n",
      "REVIEW TEXT: but...but! its mean spirited!\n",
      "cmon now. of course people support stronger vetting procedures from fa ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: That tolerant left again. ...\n",
      "\n",
      "TRUE LABEL: 0\n",
      "PREDICTED LABEL: 1\n",
      "REVIEW TEXT: Now this is a man I want to be housed with unaccompanied children.  ...\n",
      "\n",
      "TRUE LABEL: 0\n",
      "PREDICTED LABEL: 1\n",
      "REVIEW TEXT: I think they're chill and should stay lol ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: the source article even tries to down play these illegal criminal aliens by labeling them as \"undocu ...\n",
      "\n",
      "TRUE LABEL: 0\n",
      "PREDICTED LABEL: 1\n",
      "REVIEW TEXT: Democrats and republicans both can agree that this isn’t right for once ...\n",
      "\n",
      "TRUE LABEL: 0\n",
      "PREDICTED LABEL: 1\n",
      "REVIEW TEXT: Have anyone in this thread been in a Mexican jail or prison?  Might want to change your point of vie ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print missclassifications: \n",
    "for _true_label, _predicted_label, _text in random.sample(list(zip(y_test_f, predicted_labels, X_test_f)), 80):\n",
    "  if _true_label != _predicted_label:\n",
    "    print('TRUE LABEL:', _true_label)\n",
    "    print('PREDICTED LABEL:', _predicted_label)\n",
    "    print('REVIEW TEXT:', _text[:100], '...')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
