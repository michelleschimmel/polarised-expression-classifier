{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93cd7ec4",
   "metadata": {
    "id": "93cd7ec4"
   },
   "source": [
    "# Training BERT Classifier for Moralisation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafe5e35",
   "metadata": {},
   "source": [
    "This notebook contains the steps for training and testing a BERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "94c02373",
   "metadata": {
    "id": "94c02373"
   },
   "outputs": [],
   "source": [
    "# import own functions written in moralisation classifier notebook (NB II) saved to .py\n",
    "from finalproject_functions import remove_bad_rows\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import ticker\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "sns.set(style='ticks', font_scale=1.2)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import compute_sample_weight\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496e19c9",
   "metadata": {
    "id": "496e19c9"
   },
   "source": [
    "## Read Required Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4aebe3f9",
   "metadata": {
    "id": "4aebe3f9"
   },
   "outputs": [],
   "source": [
    "# read required data\n",
    "labelled_posts = pd.read_excel(\"labs_labelled_posts_new.xlsx\")\n",
    "unlabelled_posts = pd.read_csv(\"unlabelled_posts_new.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466bce40",
   "metadata": {
    "id": "466bce40"
   },
   "source": [
    "## Data Preprocessing: Remove Duplicates & NA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d4c61074",
   "metadata": {
    "id": "d4c61074"
   },
   "outputs": [],
   "source": [
    "# apply preprocessing function\n",
    "labelled_posts = remove_bad_rows(labelled_posts, \"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1848f1e",
   "metadata": {
    "id": "a1848f1e"
   },
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "377b8dba",
   "metadata": {
    "id": "377b8dba"
   },
   "outputs": [],
   "source": [
    "# store values as list required for BERT input\n",
    "x_list = labelled_posts[\"title\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c819f5b3",
   "metadata": {
    "id": "c819f5b3"
   },
   "outputs": [],
   "source": [
    "# store values as list required for BERT input\n",
    "y_list = labelled_posts[\"moral_label\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ab5ff0e0",
   "metadata": {
    "id": "ab5ff0e0"
   },
   "outputs": [],
   "source": [
    "# Train Test Split using the preprocessed comments column and the overall morality label. \n",
    "# X_test_f and y_test_f are set aside to test the final model.\n",
    "X_train, X_test_f, y_train, y_test_f = train_test_split(\n",
    "    x_list,\n",
    "    y_list,\n",
    "    test_size=0.2,\n",
    "    random_state=99)\n",
    "\n",
    "# Split the training data again, this time with test size = .25 to achieve a final split of \n",
    "# 60 training data; 20 validation data (this is where baseline is tested on); 20 final testing data (best model testing)\n",
    "X_train_sec, X_val, y_train_sec, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.25,\n",
    "    random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "660f772c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "660f772c",
    "outputId": "b3731d88-ab65-41e3-f1d4-1a26ddd500a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 588\n",
      "Validation data: 196\n",
      "Test data: 197\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data: {len(X_train_sec)}\")\n",
    "print(f\"Validation data: {len(X_val)}\")\n",
    "print(f\"Test data: {len(X_test_f)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fd131c",
   "metadata": {
    "id": "f0fd131c"
   },
   "source": [
    "## Loading the English-language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "824ccd50",
   "metadata": {
    "id": "824ccd50"
   },
   "outputs": [],
   "source": [
    "# call the english language base cased BERT\n",
    "bertmodel = 'bert-base-cased'\n",
    "\n",
    "device_name = 'cuda'\n",
    "\n",
    "max_length = 512\n",
    "\n",
    "save_directory = 'moralisation_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e248d3d",
   "metadata": {
    "id": "6e248d3d"
   },
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d932e228",
   "metadata": {
    "id": "d932e228"
   },
   "outputs": [],
   "source": [
    "# Assign the preprained tokenizer to object \n",
    "tokenizer = AutoTokenizer.from_pretrained(bertmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ce09e1c0",
   "metadata": {
    "id": "ce09e1c0"
   },
   "outputs": [],
   "source": [
    " # Creating a set containing unique labels iterating over the training labels\n",
    "unique_labels = set(label for label in y_train_sec)\n",
    "\n",
    "# Create mapping between each unique label and its corresponding ID\n",
    "label2id = {label: id for id, label in enumerate(unique_labels)}\n",
    "\n",
    "# Creates reverse mapping between ID and corresponding label\n",
    "id2label = {id: label for label, id in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40064fc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40064fc2",
    "outputId": "efdf50e5-7194-4c1e-d93a-64744efb7c1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check: \n",
    "label2id.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "86d5d4fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86d5d4fa",
    "outputId": "b91a466e-e4a0-4dd3-9f10-bc6a5ffc55ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check: \n",
    "id2label.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "587d9362",
   "metadata": {
    "id": "587d9362"
   },
   "outputs": [],
   "source": [
    "# apply tokenizer to x_train sec, ensure same lengths of tokenized sequences\n",
    "train_encodings = tokenizer(X_train_sec, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "# apply tokenizer, get validation data\n",
    "val_encodings = tokenizer(X_val, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "# apply tokenizer, get test data\n",
    "test_encodings  = tokenizer(X_test_f, truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "# map each label in the data to their corresponding ids:\n",
    "train_labels_encoded = [label2id[y] for y in y_train_sec]\n",
    "val_labels_encoded = [label2id[y] for y in y_val]\n",
    "test_labels_encoded  = [label2id[y] for y in y_test_f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d03db12",
   "metadata": {
    "id": "0d03db12"
   },
   "source": [
    "## Custom Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "01bc131f",
   "metadata": {
    "id": "01bc131f"
   },
   "outputs": [],
   "source": [
    "#Initiate MyDataset Class\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "01e457a2",
   "metadata": {
    "id": "01e457a2"
   },
   "outputs": [],
   "source": [
    "#convert the data to the training, validation and testing datasets\n",
    "train_dataset = MyDataset(train_encodings, train_labels_encoded)\n",
    "val_dataset = MyDataset(val_encodings, val_labels_encoded)\n",
    "test_dataset = MyDataset(test_encodings, test_labels_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8886880",
   "metadata": {
    "id": "f8886880"
   },
   "source": [
    "## Pre-Trained Bert Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9ee605b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ee605b1",
    "outputId": "5a2d997c-6615-41de-e3a4-7d80ed1f880e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_m = AutoModelForSequenceClassification.from_pretrained(bertmodel, num_labels=len(id2label)).to(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebebeff",
   "metadata": {
    "id": "5ebebeff"
   },
   "source": [
    "## Fine-Tuning Bert Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4ebcacaa",
   "metadata": {
    "id": "4ebcacaa"
   },
   "outputs": [],
   "source": [
    "# Function to compute the metrics for the model\n",
    "def compute_metrics(eval_pred):\n",
    "    labels = eval_pred.label_ids\n",
    "    preds = eval_pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average='macro', sample_weight=compute_sample_weight('balanced', labels))\n",
    "    return {'accuracy': acc, 'macro_f1': macro_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c07eefc0",
   "metadata": {
    "id": "c07eefc0"
   },
   "outputs": [],
   "source": [
    "# Specifying F1 score as desired metric\n",
    "metric_name = 'macro_f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0542f373",
   "metadata": {
    "id": "0542f373"
   },
   "outputs": [],
   "source": [
    "# Instantiate an object of the TrainingArguments class with the following parameters:\n",
    "training_args = TrainingArguments(\n",
    "    \n",
    "    # Number of training epochs\n",
    "    num_train_epochs=2, #with 5, 3 epochs, it began to overfit (see next script for old values)- changed to 2, now it is cutting off before overfitting\n",
    "    \n",
    "    # Batch size for training\n",
    "    per_device_train_batch_size=8, # this should be increased and outcomes for metric examined, however, computationally this was not possible\n",
    "    \n",
    "    # Batch size for evaluation\n",
    "    per_device_eval_batch_size=8,\n",
    "    \n",
    "    # Learning rate for optimization\n",
    "    learning_rate=5e-5, # lower learning rates did not produce better results\n",
    "    \n",
    "    # Load the best model at the end of training\n",
    "    load_best_model_at_end=True,\n",
    "    \n",
    "    # Metric used for selecting the best model\n",
    "    metric_for_best_model=metric_name,\n",
    "    \n",
    "    # Number of warmup steps for the optimizer\n",
    "    warmup_steps=0,\n",
    "    \n",
    "    # L2 regularization weight decay\n",
    "    weight_decay=0.01, # to avoid overfitting, this was increased, but it did not produce better results\n",
    "    \n",
    "    # Directory to save the fine-tuned model and configuration files\n",
    "    output_dir='./results',\n",
    "    \n",
    "    # Directory to store logs\n",
    "    logging_dir='./logs',\n",
    "    \n",
    "    # Log results every n steps\n",
    "    logging_steps=20,\n",
    "    \n",
    "    # Strategy for evaluating the model during training\n",
    "    evaluation_strategy='steps',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "16921d32",
   "metadata": {
    "id": "16921d32"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_m,                         # the instantiated Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,           # evaluation dataset (usually a validation set; here we just send our test set)\n",
    "    compute_metrics=compute_metrics)      # our custom evaluation function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a29f9c68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "a29f9c68",
    "outputId": "40ad5703-18e1-4012-c526-e58ef2c4dc26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='148' max='148' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [148/148 00:11, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>0.547965</td>\n",
       "      <td>0.729592</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.503600</td>\n",
       "      <td>0.488165</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.582995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.493076</td>\n",
       "      <td>0.790816</td>\n",
       "      <td>0.591043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.516800</td>\n",
       "      <td>0.450124</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.657204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.534255</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.529983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.433551</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.685359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.318600</td>\n",
       "      <td>0.429269</td>\n",
       "      <td>0.790816</td>\n",
       "      <td>0.649333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=148, training_loss=0.45138452987413147, metrics={'train_runtime': 11.2351, 'train_samples_per_second': 104.672, 'train_steps_per_second': 13.173, 'total_flos': 35051325906240.0, 'train_loss': 0.45138452987413147, 'epoch': 2.0})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49a9f6",
   "metadata": {
    "id": "2b49a9f6"
   },
   "source": [
    "## Save fine tuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f53d3331",
   "metadata": {
    "id": "f53d3331"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf539b5",
   "metadata": {
    "id": "5bf539b5"
   },
   "source": [
    "## Testing on Validation Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6e5e044e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "6e5e044e",
    "outputId": "8be808d6-5e2b-4215-adf9-86d294cbf407"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.43155258893966675,\n",
       " 'eval_accuracy': 0.7959183673469388,\n",
       " 'eval_macro_f1': 0.6696932061175933,\n",
       " 'eval_runtime': 0.4511,\n",
       " 'eval_samples_per_second': 434.518,\n",
       " 'eval_steps_per_second': 55.423,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0901e3c9",
   "metadata": {
    "id": "0901e3c9"
   },
   "source": [
    "## Evaluate on Test Set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eb03f9b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "eb03f9b3",
    "outputId": "2fbae989-d4cd-4b1e-e4b1-51677cab1280"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_results = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e39d29c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e39d29c2",
    "outputId": "6cd369eb-8d52-4ed7-efc9-8da3c35903aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 2)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_results.predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3bd849ae",
   "metadata": {
    "id": "3bd849ae"
   },
   "outputs": [],
   "source": [
    "# Highest probability prediction\n",
    "predicted_labels = predicted_results.predictions.argmax(-1) \n",
    "\n",
    "# Flatten predictions to ID list\n",
    "predicted_labels = predicted_labels.flatten().tolist()    \n",
    "\n",
    "# Convert from integers to strings \n",
    "predicted_labels = [id2label[l] for l in predicted_labels]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "225caa4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "225caa4d",
    "outputId": "13e1f0c6-5c21-4139-989a-e47576b944c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f5efa709",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5efa709",
    "outputId": "6991d679-0b7e-4d8d-8250-11257dd70d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84       128\n",
      "           1       0.80      0.46      0.59        69\n",
      "\n",
      "    accuracy                           0.77       197\n",
      "   macro avg       0.78      0.70      0.71       197\n",
      "weighted avg       0.78      0.77      0.75       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get classification report for the predicted labels\n",
    "print(classification_report(y_test_f, \n",
    "                           predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63d7de",
   "metadata": {
    "id": "5f63d7de"
   },
   "source": [
    "## Evaluation of Final Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "abe35714",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abe35714",
    "outputId": "3b7fc2b4-5ca1-496d-80a2-b76474859473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 0\n",
      "REVIEW TEXT: Canada's immigration website just crashed ...\n",
      "\n",
      "LABEL: 1\n",
      "REVIEW TEXT: Media outlets take Trump out of context to suggest he called undocumented immigrants 'animals' ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Immigration as Economic Warfare ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Fontana man sent to prison for posing as an immigration officer ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Trump announces tariffs on Mexico until 'immigration remedied' ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Trump immigration figure changes famous immigrant quote ...\n",
      "\n",
      "LABEL: 1\n",
      "REVIEW TEXT: South Jersey Restaurant Owner Outraged After ‘Don’t Tip Immigrants’ Found Written On Check ...\n",
      "\n",
      "LABEL: 1\n",
      "REVIEW TEXT: Police provide an update on the illegal immigrant fugitive wanted in the murder of a California poli ...\n",
      "\n",
      "LABEL: 1\n",
      "REVIEW TEXT: NEW JERSEY MUSLIM immigrant charged with scouting locations in major U.S. cities for multiple terror ...\n",
      "\n",
      "LABEL: 1\n",
      "REVIEW TEXT: Lawyer: Mollie Tibbetts murder suspect is not an illegal immigrant ...\n",
      "\n",
      "LABEL: 1\n",
      "REVIEW TEXT: ICE Kept 92 Immigrants Shackled On A Plane For Two Days In 'Slave Ship' Conditions, Advocates Say ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: San Francisco hopes to hire lawyers for illegal immigrants ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Trump says he is suspending immigration, need to protect jobs ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Mexican ‘DREAMer’ nabbed in immigrant crackdown ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Michigan receiving detained immigrant children as young as 3 months old ...\n",
      "\n",
      "LABEL: 0\n",
      "REVIEW TEXT: Trump Administration Will Seek To Limit Green Cards For Immigrants Needing Public Aid ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print examples of correct predictions\n",
    "for _true_label, _predicted_label, _text in random.sample(list(zip(y_test_f, predicted_labels, X_test_f)), 20):\n",
    "  if _true_label == _predicted_label:\n",
    "    print('LABEL:', _true_label)\n",
    "    print('REVIEW TEXT:', _text[:100], '...')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8bc82ab5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bc82ab5",
    "outputId": "ba026ec0-3548-4952-d255-eb3292b84ca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE LABEL: 0\n",
      "PREDICTED LABEL: 1\n",
      "REVIEW TEXT: Immigrant Detained After Press Conference ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: A computer engineer who worked under contract for the U.S. Department of Immigration and Customs Enf ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Veterans Day disgrace: Stop deporting immigrants who served ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: H.R.1044/S386 - Fairness for High-Skilled Immigrants Act of 2019: Altruistic Fair Amendment or Giant ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Best News: Immigrants Broke in to Moving Car Transporter ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Trump vows mass immigration arrests, removals of ‘millions of illegal aliens’ starting next week ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: DOCTORS CAUGHT FAKING MEDICAL RECORDS TO HELP IMMIGRANTS GET CITIZENSHIP! ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: US immigration ban: Thousands gather outside airports as anti-Trump protests hit the country ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Boston-area judge charged with helping undocumented immigrant escape courthouse to elude ICE ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Recruiter for ICE’s fake university sentenced to 6 months in jail. ICE created the Farmington Univer ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Unholy Escort humanizes immigration debate with Virgin Mary in handcuffs ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Obama's open-door immigration policy blamed for surge in rural gang crime ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: Swedish Cop Posts Epic Facebook Rant On Immigrant Crime; Ignites Nationwide Firestorm ...\n",
      "\n",
      "TRUE LABEL: 1\n",
      "PREDICTED LABEL: 0\n",
      "REVIEW TEXT: President Trump thinks immigrants are bad for America - YouTube ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print missclassifications: \n",
    "for _true_label, _predicted_label, _text in random.sample(list(zip(y_test_f, predicted_labels, X_test_f)), 80):\n",
    "  if _true_label != _predicted_label:\n",
    "    print('TRUE LABEL:', _true_label)\n",
    "    print('PREDICTED LABEL:', _predicted_label)\n",
    "    print('REVIEW TEXT:', _text[:100], '...')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d_5nI6iHP-b",
   "metadata": {
    "id": "9d_5nI6iHP-b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
